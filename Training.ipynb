{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9208775945145141243\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import os\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss\n",
    "import shutil\n",
    "from IPython.display import display\n",
    "import importlib\n",
    "\n",
    "posters_dir = os.path.join('.', 'posters')\n",
    "model_save_path = os.path.join('.', 'best_keras_model.h5py')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original: (26585, 9)\n",
      "Shape filtered: (10874, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>release_year</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>language</th>\n",
       "      <th>local_poster_file</th>\n",
       "      <th>genres_splitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>114709</td>\n",
       "      <td>862</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/rhIRbceoE9lR4v...</td>\n",
       "      <td>en</td>\n",
       "      <td>1.jpg</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>113497</td>\n",
       "      <td>8844</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/vgpXmVaVyUL7GG...</td>\n",
       "      <td>en</td>\n",
       "      <td>2.jpg</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>113228</td>\n",
       "      <td>15602</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/6ksm1sjKMFLbO7...</td>\n",
       "      <td>en</td>\n",
       "      <td>3.jpg</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>114885</td>\n",
       "      <td>31357</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/16XOMpEaLWkrcP...</td>\n",
       "      <td>en</td>\n",
       "      <td>4.jpg</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>113041</td>\n",
       "      <td>11862</td>\n",
       "      <td>1995</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/e64sOI48hQXyru...</td>\n",
       "      <td>en</td>\n",
       "      <td>5.jpg</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  imdbId  tmdbId  release_year  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  114709     862          1995   \n",
       "1                   Adventure|Children|Fantasy  113497    8844          1995   \n",
       "2                               Comedy|Romance  113228   15602          1995   \n",
       "3                         Comedy|Drama|Romance  114885   31357          1995   \n",
       "4                                       Comedy  113041   11862          1995   \n",
       "\n",
       "                                          poster_url language  \\\n",
       "0  https://image.tmdb.org/t/p/w300/rhIRbceoE9lR4v...       en   \n",
       "1  https://image.tmdb.org/t/p/w300/vgpXmVaVyUL7GG...       en   \n",
       "2  https://image.tmdb.org/t/p/w300/6ksm1sjKMFLbO7...       en   \n",
       "3  https://image.tmdb.org/t/p/w300/16XOMpEaLWkrcP...       en   \n",
       "4  https://image.tmdb.org/t/p/w300/e64sOI48hQXyru...       en   \n",
       "\n",
       "  local_poster_file                                    genres_splitted  \n",
       "0             1.jpg  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "1             2.jpg                     [Adventure, Children, Fantasy]  \n",
       "2             3.jpg                                  [Comedy, Romance]  \n",
       "3             4.jpg                           [Comedy, Drama, Romance]  \n",
       "4             5.jpg                                           [Comedy]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import helpers\n",
    "importlib.reload(helpers)\n",
    "\n",
    "movies = pd.read_csv('extended_movie_data_with_local_files.csv', sep=';')\n",
    "print('Shape original: {}'.format(movies.shape))\n",
    "movies = helpers.filter_movies(movies)\n",
    "movies['release_year'] = pd.to_numeric(movies.release_year)\n",
    "movies.dropna()\n",
    "print('Shape filtered: {}'.format(movies.shape))\n",
    "\n",
    "movies['genres_splitted'] = movies['genres'].apply(lambda x: x.split('|'))\n",
    "\n",
    "display(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>count</th>\n",
       "      <th>distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drama</td>\n",
       "      <td>4801</td>\n",
       "      <td>0.222032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>3496</td>\n",
       "      <td>0.161680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>2172</td>\n",
       "      <td>0.100449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>1729</td>\n",
       "      <td>0.079961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romance</td>\n",
       "      <td>1468</td>\n",
       "      <td>0.067891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Action</td>\n",
       "      <td>1418</td>\n",
       "      <td>0.065578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Horror</td>\n",
       "      <td>1152</td>\n",
       "      <td>0.053277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Crime</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.052907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>826</td>\n",
       "      <td>0.038200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>661</td>\n",
       "      <td>0.030569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>569</td>\n",
       "      <td>0.026315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children</td>\n",
       "      <td>560</td>\n",
       "      <td>0.025898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>535</td>\n",
       "      <td>0.024742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animation</td>\n",
       "      <td>438</td>\n",
       "      <td>0.020256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>War</td>\n",
       "      <td>281</td>\n",
       "      <td>0.012995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Musical</td>\n",
       "      <td>262</td>\n",
       "      <td>0.012117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Western</td>\n",
       "      <td>88</td>\n",
       "      <td>0.004070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          genre  count  distribution\n",
       "6         Drama   4801      0.222032\n",
       "3        Comedy   3496      0.161680\n",
       "9      Thriller   2172      0.100449\n",
       "15  Documentary   1729      0.079961\n",
       "5       Romance   1468      0.067891\n",
       "7        Action   1418      0.065578\n",
       "10       Horror   1152      0.053277\n",
       "8         Crime   1144      0.052907\n",
       "0     Adventure    826      0.038200\n",
       "12       Sci-Fi    661      0.030569\n",
       "11      Mystery    569      0.026315\n",
       "2      Children    560      0.025898\n",
       "4       Fantasy    535      0.024742\n",
       "1     Animation    438      0.020256\n",
       "13          War    281      0.012995\n",
       "14      Musical    262      0.012117\n",
       "16      Western     88      0.004070\n",
       "17    Film-Noir     23      0.001064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: \n",
      "[['Comedy', 'Romance']]\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]]\n",
      "Count of classes: 18\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def count_classes(genres_per_movie):\n",
    "    flat_list = [genre for movie_genres in genres_per_movie for genre in movie_genres]\n",
    "    genre_counts = Counter(flat_list)\n",
    "    df = pd.DataFrame(list(genre_counts.items()), columns=['genre', 'count'])\n",
    "    df = df.sort_values(['count'], ascending=False)\n",
    "    df['distribution'] = df['count']/df['count'].sum()\n",
    "    return df\n",
    "\n",
    "genre_counts = count_classes(movies['genres_splitted'])\n",
    "display(genre_counts)\n",
    "\n",
    "label_binarizer = MultiLabelBinarizer()\n",
    "label_binarizer.fit(movies['genres_splitted'])\n",
    "\n",
    "print('\\nExample: ')\n",
    "example = [movies.iloc[2]['genres_splitted']]\n",
    "print(example)\n",
    "print(label_binarizer.transform(example))\n",
    "print('Count of classes: {}'.format(len(label_binarizer.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre count average 1.9885046900864447\n",
      "Genre count variance 1.0729780289002029\n"
     ]
    }
   ],
   "source": [
    "lengths_of_genres = movies['genres_splitted'].apply(lambda x: len(x))\n",
    "genres_count_average = np.mean(lengths_of_genres)\n",
    "print('Genre count average {}'.format(genres_count_average))\n",
    "genres_count_variance = np.var(lengths_of_genres)\n",
    "print('Genre count variance {}'.format(genres_count_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>release_year</th>\n",
       "      <th>poster_url</th>\n",
       "      <th>language</th>\n",
       "      <th>local_poster_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>763</td>\n",
       "      <td>Last of the High Kings, The (a.k.a. Summer Fli...</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>116833</td>\n",
       "      <td>63564</td>\n",
       "      <td>1996</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/zMhtL7emeyMcIH...</td>\n",
       "      <td>en</td>\n",
       "      <td>763.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12680</th>\n",
       "      <td>60293</td>\n",
       "      <td>Wackness, The (2008)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>1082886</td>\n",
       "      <td>13990</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/ut8kXvFz7OUa9r...</td>\n",
       "      <td>en</td>\n",
       "      <td>60293.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26308</th>\n",
       "      <td>129514</td>\n",
       "      <td>George Carlin: It's Bad for Ya! (2008)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>963207</td>\n",
       "      <td>13643</td>\n",
       "      <td>2008</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/qRKCt403iRtcIg...</td>\n",
       "      <td>en</td>\n",
       "      <td>129514.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15313</th>\n",
       "      <td>78776</td>\n",
       "      <td>Hannah Free (2009)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1315214</td>\n",
       "      <td>39334</td>\n",
       "      <td>2009</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/zTfyE9n1SyNdIg...</td>\n",
       "      <td>en</td>\n",
       "      <td>78776.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11962</th>\n",
       "      <td>54768</td>\n",
       "      <td>Daddy Day Camp (2007)</td>\n",
       "      <td>Children|Comedy</td>\n",
       "      <td>462244</td>\n",
       "      <td>14144</td>\n",
       "      <td>2007</td>\n",
       "      <td>https://image.tmdb.org/t/p/w300/fhuhSVb3j8SShe...</td>\n",
       "      <td>en</td>\n",
       "      <td>54768.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                                              title  \\\n",
       "739        763  Last of the High Kings, The (a.k.a. Summer Fli...   \n",
       "12680    60293                               Wackness, The (2008)   \n",
       "26308   129514             George Carlin: It's Bad for Ya! (2008)   \n",
       "15313    78776                                 Hannah Free (2009)   \n",
       "11962    54768                              Daddy Day Camp (2007)   \n",
       "\n",
       "                     genres   imdbId  tmdbId  release_year  \\\n",
       "739            Comedy|Drama   116833   63564          1996   \n",
       "12680  Comedy|Drama|Romance  1082886   13990          2008   \n",
       "26308                Comedy   963207   13643          2008   \n",
       "15313                 Drama  1315214   39334          2009   \n",
       "11962       Children|Comedy   462244   14144          2007   \n",
       "\n",
       "                                              poster_url language  \\\n",
       "739    https://image.tmdb.org/t/p/w300/zMhtL7emeyMcIH...       en   \n",
       "12680  https://image.tmdb.org/t/p/w300/ut8kXvFz7OUa9r...       en   \n",
       "26308  https://image.tmdb.org/t/p/w300/qRKCt403iRtcIg...       en   \n",
       "15313  https://image.tmdb.org/t/p/w300/zTfyE9n1SyNdIg...       en   \n",
       "11962  https://image.tmdb.org/t/p/w300/fhuhSVb3j8SShe...       en   \n",
       "\n",
       "      local_poster_file  \n",
       "739             763.jpg  \n",
       "12680         60293.jpg  \n",
       "26308        129514.jpg  \n",
       "15313         78776.jpg  \n",
       "11962         54768.jpg  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_validation = train_test_split(movies, test_size=0.1, random_state=1)\n",
    "X_train, X_test = train_test_split(X_train, test_size=0.1, random_state=1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10518518518518519"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_test = X_test.genres.tolist()\n",
    "genres_test = list(map(lambda x: x.split('|'), genres_test))\n",
    "labels_test = label_binarizer.transform(genres_test)\n",
    "hamming_loss(labels_test, np.zeros(labels_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingAverage:\n",
    "    def __init__(self):\n",
    "        self._values = []\n",
    "    \n",
    "    def put(self, value):\n",
    "        self._values.append(value)\n",
    "        \n",
    "    def average(self):\n",
    "        return np.mean(self._values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "img_width, img_height = 224, 224\n",
    "#img_width, img_height = 299, 299\n",
    "\n",
    "def batch_generator(dataframe, distortion=False):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=False\n",
    "    )   \n",
    "\n",
    "    row_generator = dataframe.sample(frac=1).iterrows()\n",
    "    \n",
    "    for batch_count in range(int(dataframe.shape[0]/batch_size)):\n",
    "        \n",
    "        batch_img = []\n",
    "        batch_labels = []\n",
    "        batch_img_files = []\n",
    "        \n",
    "        for img_count in range(batch_size):\n",
    "            _, row = next(row_generator)\n",
    "\n",
    "            img_path = os.path.join(posters_dir, row['poster_img'])\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img = img_to_array(img)\n",
    "            if hasattr(img, 'close'):\n",
    "                img.close()\n",
    "            if distortion:\n",
    "                img = train_datagen.random_transform(img)\n",
    "            img = train_datagen.standardize(img)\n",
    "\n",
    "            label_list = row['genres'].split('|')\n",
    "            label = label_binarizer.transform([label_list])[0]\n",
    "\n",
    "            batch_img.append(img)\n",
    "            batch_labels.append(label)\n",
    "            batch_img_files.append(row['poster_img'])\n",
    "\n",
    "        yield [np.array(batch_img), np.array(batch_labels), batch_img_files]\n",
    "            \n",
    "    return\n",
    "\n",
    "#print(X_train.shape)\n",
    "#next(batch_generator(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_5:0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.layers import concatenate\n",
    "\n",
    "base_model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "#base_model = applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width, img_height, 3))\n",
    "\n",
    "print(base_model.input.name)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "#fg_distribution = Input(shape=(len(label_binarizer.classes_),), name='fg_distribution')\n",
    "#densities = Input(shape=(1,) , name='densities')\n",
    "#x = concatenate([x, fg_distribution, densities])\n",
    "#x = Flatten()(x)\n",
    "\n",
    "predictions = Dense(len(label_binarizer.classes_), activation='sigmoid')(x)\n",
    "model = Model(inputs=[base_model.input], outputs=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.525"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_hamming_loss(labels, batch):\n",
    "    predictions_sigmoid = model.predict_on_batch(batch_inputs)\n",
    "    predictions = np.where(predictions_sigmoid > 0.5, 1, 0)\n",
    "    return hamming_loss(batch_labels, predictions)\n",
    "\n",
    "x, labels, _ = next(batch_generator(X_train))\n",
    "calc_hamming_loss(labels, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches 10, Train Loss: 4.741, Hamming Loss: 0.124\n",
      "Batches 20, Train Loss: 4.955, Hamming Loss: 0.125\n",
      "Batches 30, Train Loss: 4.846, Hamming Loss: 0.128\n",
      "Batches 40, Train Loss: 4.836, Hamming Loss: 0.131\n",
      "Batches 50, Train Loss: 4.848, Hamming Loss: 0.130\n",
      "Batches 60, Train Loss: 4.886, Hamming Loss: 0.130\n",
      "Batches 70, Train Loss: 4.933, Hamming Loss: 0.131\n",
      "Batches 80, Train Loss: 4.903, Hamming Loss: 0.130\n",
      "Batches 90, Train Loss: 4.890, Hamming Loss: 0.130\n",
      "Batches 100, Train Loss: 4.849, Hamming Loss: 0.127\n",
      "Epoch: 0, Validation Loss: 0.094\n",
      "Batches 10, Train Loss: 4.742, Hamming Loss: 0.123\n",
      "Batches 20, Train Loss: 4.781, Hamming Loss: 0.125\n",
      "Batches 30, Train Loss: 4.784, Hamming Loss: 0.123\n",
      "Batches 40, Train Loss: 4.815, Hamming Loss: 0.123\n",
      "Batches 50, Train Loss: 4.739, Hamming Loss: 0.122\n",
      "Batches 60, Train Loss: 4.734, Hamming Loss: 0.121\n",
      "Batches 70, Train Loss: 4.763, Hamming Loss: 0.121\n",
      "Batches 80, Train Loss: 4.711, Hamming Loss: 0.120\n",
      "Batches 90, Train Loss: 4.690, Hamming Loss: 0.118\n",
      "Batches 100, Train Loss: 4.710, Hamming Loss: 0.117\n",
      "Epoch: 1, Validation Loss: 0.092\n",
      "Batches 10, Train Loss: 4.998, Hamming Loss: 0.121\n",
      "Batches 20, Train Loss: 4.668, Hamming Loss: 0.114\n",
      "Batches 30, Train Loss: 4.651, Hamming Loss: 0.111\n",
      "Batches 40, Train Loss: 4.637, Hamming Loss: 0.110\n",
      "Batches 50, Train Loss: 4.586, Hamming Loss: 0.108\n",
      "Batches 60, Train Loss: 4.546, Hamming Loss: 0.107\n",
      "Batches 70, Train Loss: 4.543, Hamming Loss: 0.106\n",
      "Batches 80, Train Loss: 4.582, Hamming Loss: 0.107\n",
      "Batches 90, Train Loss: 4.600, Hamming Loss: 0.107\n",
      "Batches 100, Train Loss: 4.618, Hamming Loss: 0.107\n",
      "Epoch: 2, Validation Loss: 0.083\n",
      "Batches 10, Train Loss: 4.739, Hamming Loss: 0.109\n",
      "Batches 20, Train Loss: 4.532, Hamming Loss: 0.104\n",
      "Batches 30, Train Loss: 4.616, Hamming Loss: 0.107\n",
      "Batches 40, Train Loss: 4.630, Hamming Loss: 0.107\n",
      "Batches 50, Train Loss: 4.546, Hamming Loss: 0.105\n",
      "Batches 60, Train Loss: 4.503, Hamming Loss: 0.104\n",
      "Batches 70, Train Loss: 4.485, Hamming Loss: 0.105\n",
      "Batches 80, Train Loss: 4.548, Hamming Loss: 0.105\n",
      "Batches 90, Train Loss: 4.524, Hamming Loss: 0.105\n",
      "Batches 100, Train Loss: 4.518, Hamming Loss: 0.104\n",
      "Epoch: 3, Validation Loss: 0.133\n",
      "Batches 10, Train Loss: 4.195, Hamming Loss: 0.094\n",
      "Batches 20, Train Loss: 4.315, Hamming Loss: 0.099\n",
      "Batches 30, Train Loss: 4.306, Hamming Loss: 0.098\n",
      "Batches 40, Train Loss: 4.271, Hamming Loss: 0.098\n",
      "Batches 50, Train Loss: 4.368, Hamming Loss: 0.100\n",
      "Batches 60, Train Loss: 4.446, Hamming Loss: 0.102\n",
      "Batches 70, Train Loss: 4.467, Hamming Loss: 0.101\n",
      "Batches 80, Train Loss: 4.503, Hamming Loss: 0.102\n",
      "Batches 90, Train Loss: 4.481, Hamming Loss: 0.102\n",
      "Batches 100, Train Loss: 4.495, Hamming Loss: 0.102\n",
      "Epoch: 4, Validation Loss: 0.097\n"
     ]
    }
   ],
   "source": [
    "best_hammond_loss = -1\n",
    "for epoch in range(5):\n",
    "    \n",
    "    count = 0\n",
    "  \n",
    "    hamming_loss_rolling = RollingAverage()\n",
    "    loss_rolling = RollingAverage()\n",
    "\n",
    "    for batch_inputs, batch_labels, _ in batch_generator(X_train, distortion=True):\n",
    "        hamming = calc_hamming_loss(batch_labels, batch_inputs)\n",
    "        hamming_loss_rolling.put(hamming)\n",
    "        loss = model.train_on_batch(batch_inputs, batch_labels)\n",
    "        loss_rolling.put(loss)\n",
    "        count += 1\n",
    "        if count % 10 == 0:\n",
    "            print('Batches {}, Train Loss: {:.3f}, Hamming Loss: {:.3f}' \\\n",
    "                  .format(count, loss_rolling.average(), hamming_loss_rolling.average()))\n",
    "    \n",
    "    test_hamming_loss_rolling = RollingAverage()\n",
    "    for test_batch_inputs, test_batch_labels, _ in batch_generator(X_validation, distortion=False):\n",
    "        test_hamming_loss_rolling.put(calc_hamming_loss(test_batch_labels, test_batch_inputs))\n",
    "        \n",
    "    if test_hamming_loss_rolling.average() > best_hammond_loss:\n",
    "        best_hammond_loss = test_hamming_loss_rolling.average()\n",
    "        model.save(model_save_path)\n",
    "\n",
    "    print('Epoch: {}, Hamming Loss: {:.3f}'\n",
    "          .format(epoch, test_hamming_loss_rolling.average()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model = load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10151515151515152"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming = RollingAverage()\n",
    "for batch_inputs, batch_labels, img_files in batch_generator(X_test, distortion=False):\n",
    "    hamming.put(calc_hamming_loss(batch_labels, batch_inputs))\n",
    "    \n",
    "hamming.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def plot_img(img_file, teached_target, labels, result):\n",
    "    plt.figure(figsize=(6,8))\n",
    "    img=mpimg.imread(os.path.join(posters_dir, img_file))\n",
    "\n",
    "    ax1 = plt.subplot(2, 1, 1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    plt.barh(range(len(labels)), list(result))\n",
    "    plt.yticks(range(len(labels)), list(labels), fontsize=12)\n",
    "    ax.set_xlim(right=1.0)\n",
    "\n",
    "    plt.gcf().text(0, 1.05, 'Teached as {}'.format(teached_target), fontsize=18)\n",
    "    plt.gcf().text(0, 1, os.path.basename(img_file), fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_classifications_path = os.path.join('.', 'classification_examples')\n",
    "\n",
    "if os.path.exists(example_classifications_path):\n",
    "    shutil.rmtree(example_classifications_path)\n",
    "\n",
    "if not os.path.exists(example_classifications_path):\n",
    "    os.makedirs(example_classifications_path)\n",
    "\n",
    "count = 0\n",
    "for batch_inputs, batch_labels, img_files  in batch_generator(X_test, distortion=False):\n",
    "    predictions = loaded_model.predict(batch_inputs)\n",
    "    for i in range(batch_inputs.shape[0]):\n",
    "        count += 1\n",
    "        encoded_label = np.expand_dims(batch_labels[i], axis=0)\n",
    "        teached_target = label_binarizer.inverse_transform(encoded_label)[0]\n",
    "        prediction = predictions[i]\n",
    "        plt = plot_img(img_files[i], teached_target, label_binarizer.classes_, prediction)\n",
    "        plt.savefig(os.path.join(example_classifications_path, img_files[i]), bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
